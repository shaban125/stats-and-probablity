{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXmkV9qvPEpT"
      },
      "outputs": [],
      "source": [
        "spam = [\n",
        "    \"To use your credit, click the new WAP link in the next years txt message or click here\",\n",
        "    \"Thanks for your subscription to New Ringtone UK your new mobile will be charged £5/month Please confirm annoncement by replying\",\n",
        "    \"As a valued customer, I am pleased to advise you that following recent delivery waiting review of your Mob No. you are awarded with. Call us to review.\",\n",
        "    \"Please call our new customer service representative on\",\n",
        "    \"We are trying to contact you. Last weekends customer draw shows that you won a £1000 prize GUARANTEED. Calling years\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam_test = [\"Customer service annoncement. You have a New Years delivery waiting for you. click\"]"
      ],
      "metadata": {
        "id": "C9WeSnn-PTs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non = [\n",
        "    \"I don't think he goes to usf, he lives around here though\",\n",
        "    \"New car and house for my parents. i have only new job in hand\",\n",
        "    \"Great escape. I fancy the bridge but needs her lager. See you tomorrow\",\n",
        "    \"Tired. I haven't slept well the past few nights.\",\n",
        "    \"Too late. I said i have the website. I didn't i have or dont have the slippers\",\n",
        "    \"I might come by tonight then if my class lets out early\",\n",
        "    \"Jos ask if u wana meet up?\",\n",
        "    \"That would be great. We'll be at the Guild. We can try meeting with the customer on Bristol road or somewhere\"\n",
        "    ]"
      ],
      "metadata": {
        "id": "w8V_963MPWTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_test_2 = [\"That would be great. We'll be at the Guild. We can try meeting with the customer on Bristol road or somewhere\"]"
      ],
      "metadata": {
        "id": "hcCqxHxuPhHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kfq55yYPiRH",
        "outputId": "da011052-83e2-40a3-8c3c-0fd61918ebd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.parsing.porter import PorterStemmer\n",
        "from gensim.utils import tokenize"
      ],
      "metadata": {
        "id": "Jn3ZYC6tPoEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_sentence = non[4]\n",
        "test_sentence = non[5]\n",
        "# test_sentence = spam[1]\n",
        "\n",
        "print(test_sentence)\n",
        "\n",
        "removed_stops = remove_stopwords(test_sentence)\n",
        "print(removed_stops)\n",
        "\n",
        "p = PorterStemmer()\n",
        "stemmed = p.stem(removed_stops)\n",
        "print(stemmed)\n",
        "\n",
        "tokens = tokenize(stemmed)\n",
        "print(list(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjv0Tb84PtyW",
        "outputId": "7d70ce5a-0fb2-4bb2-9ad3-d4da0989364f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I might come by tonight then if my class lets out early\n",
            "I come tonight class lets early\n",
            "i come tonight class lets earli\n",
            "['i', 'come', 'tonight', 'class', 'lets', 'earli']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentence(sentence):\n",
        "    p = PorterStemmer()\n",
        "    removed_stops = remove_stopwords(sentence)\n",
        "    stemmed = p.stem(removed_stops)\n",
        "    tokens = tokenize(stemmed)\n",
        "    return list(tokens)"
      ],
      "metadata": {
        "id": "mkQjHLSQRYIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = set()     # will have unique values only\n",
        "spams_tokenized = []\n",
        "nons_tokenized = []\n",
        "\n",
        "\n",
        "for sentence in spam:\n",
        "    sentence_tokens = tokenize_sentence(sentence)\n",
        "    spams_tokenized.append(sentence_tokens)\n",
        "    dictionary  = dictionary.union(sentence_tokens)   # add sentence words to the dictionary\n",
        "\n",
        "\n",
        "\n",
        "for sentence in non:\n",
        "    sentence_tokens = tokenize_sentence(sentence)\n",
        "    nons_tokenized.append(sentence_tokens)\n",
        "    dictionary  = dictionary.union(sentence_tokens)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Tokenized spam: \", spams_tokenized)\n",
        "print(\"Tokenized non:  \", nons_tokenized)\n",
        "print(\"Dictionary:     \", dictionary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3rT9RW0R9xV",
        "outputId": "1caec0f3-2400-49b7-8938-c55773099f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized spam:  [['to', 'use', 'credit', 'click', 'new', 'wap', 'link', 'years', 'txt', 'message', 'click'], ['thanks', 'subscription', 'new', 'ringtone', 'uk', 'new', 'mobile', 'charged', 'month', 'please', 'confirm', 'annoncement', 'repli'], ['as', 'valued', 'customer', 'i', 'pleased', 'advise', 'following', 'recent', 'delivery', 'waiting', 'review', 'mob', 'no', 'awarded', 'with', 'call', 'review'], ['please', 'new', 'customer', 'service', 'repres'], ['we', 'trying', 'contact', 'you', 'last', 'weekends', 'customer', 'draw', 'shows', 'won', 'prize', 'guaranteed', 'calling', 'year']]\n",
            "Tokenized non:   [['i', 'don', 't', 'think', 'goes', 'usf', 'l'], ['new', 'car', 'house', 'parents', 'new', 'job', 'hand'], ['great', 'escape', 'i', 'fancy', 'bridge', 'needs', 'lager', 'see', 'tomorrow'], ['tired', 'i', 'haven', 't', 'slept', 'past', 'nights'], ['too', 'late', 'i', 'said', 'website', 'i', 'didn', 't', 'dont', 'slipp'], ['i', 'come', 'tonight', 'class', 'lets', 'earli'], ['jos', 'ask', 'u', 'wana', 'meet', 'up'], ['that', 'great', 'we', 'll', 'guild', 'we', 'try', 'meeting', 'customer', 'bristol', 'road']]\n",
            "Dictionary:      {'wap', 'shows', 'goes', 'charged', 'haven', 'won', 'click', 'guaranteed', 'following', 'guild', 'subscription', 'repli', 'weekends', 'think', 'late', 'jos', 'slipp', 'review', 'prize', 'waiting', 'thanks', 'valued', 'confirm', 'month', 'annoncement', 'years', 'year', 'repres', 'contact', 'nights', 'customer', 'earli', 'usf', 'parents', 'as', 'that', 'you', 'tomorrow', 'mob', 'l', 'don', 'pleased', 'credit', 'calling', 'new', 'mobile', 'ask', 'needs', 'trying', 'meet', 'delivery', 'ringtone', 'tired', 'i', 'car', 'too', 'class', 'advise', 'tonight', 'draw', 'website', 'message', 'didn', 'no', 'escape', 'past', 'hand', 'call', 'road', 'to', 'said', 'lager', 'slept', 'try', 'service', 'u', 'great', 'bridge', 'lets', 'bristol', 'link', 'wana', 'up', 'meeting', 't', 'last', 'recent', 'job', 'll', 'see', 'house', 'please', 'with', 'dont', 'txt', 'awarded', 'use', 'uk', 'we', 'fancy', 'come'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_word_count = len(dictionary)\n",
        "total_spam_messages = len(spams_tokenized)\n",
        "total_all_messages = len(spams_tokenized) + len(nons_tokenized)\n",
        "\n",
        "print(\"Total Number of words: \", total_word_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0sdg_o8TnXG",
        "outputId": "31fd9618-6a21-4562-aa3f-561b01ea372e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of words:  101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P(spam) ... does not depend on an individual word so let's calculate that separately once\n",
        "\n",
        "p_spam = total_spam_messages / total_all_messages\n",
        "\n",
        "print(\"P(spam) = \", p_spam)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DiUFohyT8yH",
        "outputId": "111c3937-103f-4b51-a68a-5e096e6ad12c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(spam) =  0.38461538461538464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to count occurances\n",
        "\n",
        "def count_word_in_messages(word, messages):\n",
        "    total_count = 0\n",
        "    for msg in messages:\n",
        "        if word in msg:       # notice this ensured uniqueness automatically\n",
        "            total_count += 1\n",
        "\n",
        "    return total_count\n"
      ],
      "metadata": {
        "id": "9PIABnIMUCYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prob = 1   # can't start from 0\n",
        "\n",
        "\n",
        "for test_sentence in spam_test:\n",
        "    test_sentence = tokenize_sentence(test_sentence)\n",
        "    print(test_sentence)\n",
        "\n",
        "    # let's run this for each word separately\n",
        "    for word in test_sentence:\n",
        "        print(\"----------------\")\n",
        "        print(\"Runnig for word:\", word)\n",
        "\n",
        "        # Find P( w | spam)\n",
        "        spam_count = count_word_in_messages(word, spams_tokenized)\n",
        "        p_w_spam = spam_count / total_spam_messages\n",
        "        print(\"P( w | spam)  = \", p_w_spam)\n",
        "\n",
        "        # Find P( w )\n",
        "        w_count = count_word_in_messages(word, spams_tokenized)\n",
        "        w_count += count_word_in_messages(word, nons_tokenized)\n",
        "        p_w = w_count / total_all_messages\n",
        "        print(\"P( w )        = \", p_w)\n",
        "\n",
        "\n",
        "        # Find P( spam | w )\n",
        "        p_spam_w = (p_w_spam * p_spam) / p_w\n",
        "        print(\"P( spam )     = \", p_spam)\n",
        "        print(\"P( spam | w ) = \", p_spam_w)\n",
        "        print(\"\")\n",
        "        final_prob *= p_spam_w\n",
        "\n",
        "    print(\"P( spam | all_words ) = \", final_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4zbABziUNxi",
        "outputId": "12da0c7a-f75d-4bcb-e83e-0ce06e53511b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['customer', 'service', 'annoncement', 'you', 'new', 'years', 'delivery', 'waiting', 'you', 'click']\n",
            "----------------\n",
            "Runnig for word: customer\n",
            "P( w | spam)  =  0.6\n",
            "P( w )        =  0.3076923076923077\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  0.75\n",
            "\n",
            "----------------\n",
            "Runnig for word: service\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: annoncement\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: you\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: new\n",
            "P( w | spam)  =  0.6\n",
            "P( w )        =  0.3076923076923077\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  0.75\n",
            "\n",
            "----------------\n",
            "Runnig for word: years\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: delivery\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: waiting\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: you\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "----------------\n",
            "Runnig for word: click\n",
            "P( w | spam)  =  0.2\n",
            "P( w )        =  0.07692307692307693\n",
            "P( spam )     =  0.38461538461538464\n",
            "P( spam | w ) =  1.0\n",
            "\n",
            "P( spam | all_words ) =  0.5625\n"
          ]
        }
      ]
    }
  ]
}